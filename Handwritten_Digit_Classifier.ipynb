{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Digit Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o7BzQRkzUlw"
      },
      "source": [
        "# **Handwritten Digit Classifier**\r\n",
        "In my first personal project for machine learning, I developed a convolutional neural network for the classification of the handwritten digits. The model is trained using the MNIST database containing 60,000 images of handwritten digits. \r\n",
        "\r\n",
        "This project is done as part of the fast.ai course \"Practical Deep Learning for Coders\" and uses certain functions from the fastai library. However, for learning purposes, the neural network is built from scratch to fully understand how a model is created and trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbKiILFhVEae"
      },
      "source": [
        "!pip install -Uqq fastbook\r\n",
        "import fastbook\r\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTh8JLMngfOD"
      },
      "source": [
        "from fastai.vision.all import *\r\n",
        "from fastbook import *\r\n",
        "\r\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsM8Q0GmYV_j"
      },
      "source": [
        "# MNIST Dataset\r\n",
        "The MNIST dataset contains 60,000  images of handwritten digits. For each digit from 0 to 9, the images are that are taken from the training set are combined into a rank-3 tensor. All of the images are then organized in a dictionary with the digit as the key and the rank-3 tensor as the value.\r\n",
        "\r\n",
        "To visualize the entire dataset, the mean of all images for each digit is displayed, representing the \"ideal\" digit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IYOeUumhFyG"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcnR4-chdKD"
      },
      "source": [
        "Path.BASE_PATH = path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh4es_AYhf0m",
        "outputId": "ca9dba86-f1cf-47aa-9827-e81082e0659d"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('testing'),Path('training')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlth-rothjQo",
        "outputId": "1acfc0c0-15c9-48e7-ff4e-10f4271b49e7"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('training/5'),Path('training/7'),Path('training/9'),Path('training/6'),Path('training/0'),Path('training/4'),Path('training/3'),Path('training/1'),Path('training/8'),Path('training/2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecvVe4u2idc8"
      },
      "source": [
        "fns = {i: [fn for fn in (path/f'training/{i}').ls()] for i in range(10)}\r\n",
        "img_tensors = {key: [tensor(Image.open(imagepath)) for imagepath in paths] for (key,paths) in fns.items()}\r\n",
        "stacked_digits = {key: torch.stack(digit).float()/255 for (key,digit) in img_tensors.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfqtumAKycxr"
      },
      "source": [
        "mean_tensors = {key: img.mean(0) for (key,img) in stacked_digits.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "Ycs21GM4yv0I",
        "outputId": "eff5aa0b-e641-46ab-ab30-bc9adea1e75a"
      },
      "source": [
        "show_images(list(mean_tensors.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x216 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpN31gFv75ub"
      },
      "source": [
        "The same dictionary of rank-3 tensors is created for the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFPuI1s9l8P"
      },
      "source": [
        "valid_fns = {i: [fn for fn in (path/f'testing/{i}').ls()] for i in range(10)}\r\n",
        "valid_img_tensors = {key: [tensor(Image.open(imagepath)) for imagepath in paths] for (key,paths) in valid_fns.items()}\r\n",
        "valid_stacked_digits = {key: torch.stack(digit).float()/255 for (key,digit) in valid_img_tensors.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCnSVo0A2YN"
      },
      "source": [
        "# Training the Model\r\n",
        "Stochastic gradient descent is implemented to train the model. The independent variable x is the images concatenated into a single rank-2 tensor and the dependent variable y is the labels. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBxNDbXN9bMg"
      },
      "source": [
        "train_x = torch.cat([digit for digit in stacked_digits.values()]).view(-1, 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZXdn1rP6__0"
      },
      "source": [
        "def create_label(rows, columns, index):\r\n",
        "  labels = torch.zeros((rows,columns))\r\n",
        "  labels[:,index] = 1\r\n",
        "  return labels\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjWOv1q-8aPI"
      },
      "source": [
        "stacked_labels = {key: create_label(tensors.shape[0], len(stacked_digits), key) for (key,tensors) in stacked_digits.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3hZgAe69QQ0",
        "outputId": "40aeb686-929d-4d68-f6a3-fb829ce2cc39"
      },
      "source": [
        "train_y = torch.cat([label for label in stacked_labels.values()])\r\n",
        "train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyPNgquY-kVO"
      },
      "source": [
        "valid_x = torch.cat([digit for digit in valid_stacked_digits.values()]).view(-1, 28*28)\r\n",
        "valid_stacked_labels = {key: create_label(tensors.shape[0], len(valid_stacked_digits), key) for (key,tensors) in valid_stacked_digits.items()}\r\n",
        "valid_y = torch.cat([label for label in valid_stacked_labels.values()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy_Gjmfp-65j"
      },
      "source": [
        "dset = list(zip(train_x,train_y))\r\n",
        "valid_dset = list(zip(valid_x,valid_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3NVe-uMBONR"
      },
      "source": [
        "dl = DataLoader(dset, batch_size=256)\r\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZm94JxoDVim"
      },
      "source": [
        "The cross entropy loss function is used to measure the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPzLxtsoM4KX"
      },
      "source": [
        "def mnist_loss(predictions, targets):\r\n",
        "  predictions = predictions.softmax(dim=1)\r\n",
        "  loss = -(targets * predictions.log()).sum() / len(predictions)\r\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF48nbWoPOUW"
      },
      "source": [
        "def init_params(size, std=1.0):\r\n",
        "  return (torch.randn(size)*std).requires_grad_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-WuqEy8PlyZ"
      },
      "source": [
        "weights = init_params((28*28,10))\r\n",
        "bias = init_params(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z806sd3RyzE"
      },
      "source": [
        "def linear1(xb): return xb@weights + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPOVQlD1TWNT"
      },
      "source": [
        "xb,yb = first(dl)\r\n",
        "preds = linear1(xb)\r\n",
        "loss = mnist_loss(preds, yb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn2pRPghVfnc"
      },
      "source": [
        "def calc_grad(xb, yb, model):\r\n",
        "  preds = model(xb)\r\n",
        "  loss = mnist_loss(preds, yb)\r\n",
        "  loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF5k2lkeV1NG"
      },
      "source": [
        "def train_epoch(model, lr, params):\r\n",
        "  for xb, yb in dl:\r\n",
        "    calc_grad(xb, yb, model)\r\n",
        "    for p in params:\r\n",
        "      p.data -= p.grad*lr\r\n",
        "      p.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8sSXtuVECK2"
      },
      "source": [
        "The model returns 10 predictions which correspond to the probability of an image belonging to every digit class. The maximum probability is thus the prediction of the model. The accuracy is determined by checking if the prediction matches the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_3aC5SkWYM8"
      },
      "source": [
        "def batch_accuracy(predictions, targets):\r\n",
        "    predictions = predictions.softmax(dim=1)\r\n",
        "    predictions_i = predictions.max(1).indices\r\n",
        "    targets_i = targets.max(1).indices\r\n",
        "    return (predictions_i == targets_i).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAUkoDJiYcRx"
      },
      "source": [
        "def validate_epoch(model):\r\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\r\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygg_4Uy0MN9"
      },
      "source": [
        "dls = DataLoaders(dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOPFDA7wHzJW"
      },
      "source": [
        "Nonlinearity is added between two linear layers, which makes our neural network. This is a rectified linear unit, which replaces every negative value with a zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43xSXja-2AiY"
      },
      "source": [
        "simple_net = nn.Sequential(\r\n",
        "    nn.Linear(28*28,128),\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Linear(128,10)\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFmtBN2H0QjS"
      },
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqNS3pR5IfIA"
      },
      "source": [
        "The model is complete. 60 epochs with a learning rate of 0.001 yields an accuracy of 86.54%. The full results are shown in the table below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MQetDZjr0ews",
        "outputId": "37ce5598-a0b8-49cc-eb81-bc1bfe3c7b7b"
      },
      "source": [
        "learn.fit(60, 0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.358382</td>\n",
              "      <td>2.279210</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.322724</td>\n",
              "      <td>2.242783</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.287781</td>\n",
              "      <td>2.203944</td>\n",
              "      <td>0.393600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.251134</td>\n",
              "      <td>2.161121</td>\n",
              "      <td>0.526100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.210732</td>\n",
              "      <td>2.113471</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.165181</td>\n",
              "      <td>2.060539</td>\n",
              "      <td>0.650600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.114166</td>\n",
              "      <td>2.001935</td>\n",
              "      <td>0.677400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.057389</td>\n",
              "      <td>1.937633</td>\n",
              "      <td>0.692200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.995081</td>\n",
              "      <td>1.868239</td>\n",
              "      <td>0.700700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.927819</td>\n",
              "      <td>1.794782</td>\n",
              "      <td>0.704800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.856632</td>\n",
              "      <td>1.718638</td>\n",
              "      <td>0.707600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.782761</td>\n",
              "      <td>1.641272</td>\n",
              "      <td>0.711300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.707641</td>\n",
              "      <td>1.564167</td>\n",
              "      <td>0.712100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.632769</td>\n",
              "      <td>1.488741</td>\n",
              "      <td>0.712800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.559519</td>\n",
              "      <td>1.416158</td>\n",
              "      <td>0.714600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.489038</td>\n",
              "      <td>1.347287</td>\n",
              "      <td>0.718800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.422155</td>\n",
              "      <td>1.282678</td>\n",
              "      <td>0.723300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.359430</td>\n",
              "      <td>1.222612</td>\n",
              "      <td>0.728600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.301047</td>\n",
              "      <td>1.167143</td>\n",
              "      <td>0.735500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.247037</td>\n",
              "      <td>1.116142</td>\n",
              "      <td>0.741000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.197205</td>\n",
              "      <td>1.069400</td>\n",
              "      <td>0.747700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.151307</td>\n",
              "      <td>1.026618</td>\n",
              "      <td>0.754300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.109042</td>\n",
              "      <td>0.987478</td>\n",
              "      <td>0.760700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.070129</td>\n",
              "      <td>0.951649</td>\n",
              "      <td>0.766800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.034290</td>\n",
              "      <td>0.918821</td>\n",
              "      <td>0.773000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.001255</td>\n",
              "      <td>0.888688</td>\n",
              "      <td>0.778000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.970729</td>\n",
              "      <td>0.860983</td>\n",
              "      <td>0.784300</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.942511</td>\n",
              "      <td>0.835449</td>\n",
              "      <td>0.789400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.916376</td>\n",
              "      <td>0.811870</td>\n",
              "      <td>0.794500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.892118</td>\n",
              "      <td>0.790049</td>\n",
              "      <td>0.797900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.869566</td>\n",
              "      <td>0.769806</td>\n",
              "      <td>0.801800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.848576</td>\n",
              "      <td>0.750985</td>\n",
              "      <td>0.805500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.828993</td>\n",
              "      <td>0.733453</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.810692</td>\n",
              "      <td>0.717083</td>\n",
              "      <td>0.812200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.793562</td>\n",
              "      <td>0.701762</td>\n",
              "      <td>0.816300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.777499</td>\n",
              "      <td>0.687399</td>\n",
              "      <td>0.819600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.762410</td>\n",
              "      <td>0.673904</td>\n",
              "      <td>0.822300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.748220</td>\n",
              "      <td>0.661200</td>\n",
              "      <td>0.824700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.734840</td>\n",
              "      <td>0.649224</td>\n",
              "      <td>0.827700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.722217</td>\n",
              "      <td>0.637913</td>\n",
              "      <td>0.830500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.710292</td>\n",
              "      <td>0.627212</td>\n",
              "      <td>0.832900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.699003</td>\n",
              "      <td>0.617075</td>\n",
              "      <td>0.835400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.688309</td>\n",
              "      <td>0.607456</td>\n",
              "      <td>0.838200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.678155</td>\n",
              "      <td>0.598323</td>\n",
              "      <td>0.840200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.668510</td>\n",
              "      <td>0.589634</td>\n",
              "      <td>0.841500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.659338</td>\n",
              "      <td>0.581359</td>\n",
              "      <td>0.842400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.650600</td>\n",
              "      <td>0.573471</td>\n",
              "      <td>0.844100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.642270</td>\n",
              "      <td>0.565941</td>\n",
              "      <td>0.846100</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.634323</td>\n",
              "      <td>0.558747</td>\n",
              "      <td>0.847400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.626727</td>\n",
              "      <td>0.551868</td>\n",
              "      <td>0.849200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.619465</td>\n",
              "      <td>0.545283</td>\n",
              "      <td>0.851300</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.612514</td>\n",
              "      <td>0.538974</td>\n",
              "      <td>0.852700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.605856</td>\n",
              "      <td>0.532924</td>\n",
              "      <td>0.854400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.599474</td>\n",
              "      <td>0.527119</td>\n",
              "      <td>0.856000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.593352</td>\n",
              "      <td>0.521544</td>\n",
              "      <td>0.857400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.587471</td>\n",
              "      <td>0.516189</td>\n",
              "      <td>0.858700</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.581815</td>\n",
              "      <td>0.511039</td>\n",
              "      <td>0.860400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.576378</td>\n",
              "      <td>0.506080</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.571142</td>\n",
              "      <td>0.501307</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.566097</td>\n",
              "      <td>0.496708</td>\n",
              "      <td>0.865400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK2O_j5xJFYe"
      },
      "source": [
        "# Furthering the Project\r\n",
        "The accuracy of the model can be increased by experimenting with a different number of epochs and a different learning rate. A different loss function can be also be used. \r\n",
        "\r\n",
        "To move the model into production, the model can be turned into a simple web application where the user can upload a series of handwritten digits to obtain the predictions of the model as the output."
      ]
    }
  ]
}